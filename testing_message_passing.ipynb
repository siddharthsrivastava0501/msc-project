{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "def sig(x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return 2*sig(2*x) - 1\n",
    "\n",
    "def dedt(E):\n",
    "    # de = (-E + (1 - r*E)*sig(w_ee*E - w_ei*I + P)) / tau_E\n",
    "    de = (-E + sig(k*E + k*P)) / tau_E\n",
    "    return de\n",
    "\n",
    "\n",
    "class Variable:\n",
    "    def __init__(self, var_id, mu, sigma, left_dynamics_id, right_dynamics_id, obs_id):\n",
    "        self.var_id = var_id\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.eta = torch.zeros_like(mu, requires_grad=True)\n",
    "        self.lmbda = torch.zeros_like(sigma, requires_grad=True)\n",
    "\n",
    "        self.right_dynamics_id = right_dynamics_id\n",
    "        self.left_dynamics_id = left_dynamics_id\n",
    "        self.obs_id = obs_id\n",
    "\n",
    "        self.factors = [self.obs_id, self.left_dynamics_id, self.right_dynamics_id]\n",
    "\n",
    "        self.out_eta, self.out_lmbda = torch.zeros_like(mu), torch.zeros_like(sigma)\n",
    "\n",
    "    def get_eta(self):\n",
    "        return self.out_eta\n",
    "    \n",
    "    def get_mu(self):\n",
    "        return self.mu\n",
    "    \n",
    "    def get_lmbda(self):\n",
    "        return self.out_lmbda\n",
    "    \n",
    "    def get_sigma(self):\n",
    "        return self.sigma\n",
    "\n",
    "    def belief_update(self):\n",
    "        eta_here, lmbda_here = torch.tensor([[0.]]), torch.tensor([[0.]])\n",
    "\n",
    "        for fid in self.factors:\n",
    "            if fid == -1: continue\n",
    "\n",
    "            eta_here  += factor_nodes[fid].get_eta()\n",
    "            lmbda_here += factor_nodes[fid].get_lmbda()\n",
    "\n",
    "        if lmbda_here == 0.: print('We Hebben Een Serieus Probleem ')\n",
    "\n",
    "        self.out_eta, self.out_lmbda = eta_here, lmbda_here\n",
    "\n",
    "        self.sigma = torch.linalg.inv(self.out_lmbda)\n",
    "        self.mu = self.sigma @ self.out_eta\n",
    "\n",
    "    def compute_messages(self):\n",
    "        self.belief_update()\n",
    "\n",
    "        if self.right_dynamics_id == -1: return\n",
    "\n",
    "        in_eta, in_lmbda = factor_nodes[self.right_dynamics_id].get_eta(), factor_nodes[self.right_dynamics_id].get_lmbda()\n",
    "\n",
    "        self.out_eta -= in_eta \n",
    "        self.out_lmbda -= in_lmbda\n",
    "\n",
    "\n",
    "class ObservationFactor:\n",
    "    def __init__(self, f_id, var_id, z, lmbda_in):\n",
    "        self.f_id = f_id\n",
    "        self.z = z\n",
    "        self.lmbda_in = lmbda_in\n",
    "        self.var_id = var_id\n",
    "\n",
    "        # Jacobian\n",
    "        J = torch.tensor([[1.]])\n",
    "\n",
    "        self.eta = (J.T @ lmbda_in) * z\n",
    "        self.lmbda = (J.T @ lmbda_in) @ J\n",
    "        self.N_sigma = torch.sqrt(lmbda_in[0,0])\n",
    "\n",
    "        self.out_eta, self.out_lmbda = self.eta, self.lmbda\n",
    "    \n",
    "    def get_eta(self):\n",
    "        return self.out_eta\n",
    "\n",
    "    def get_lmbda(self):\n",
    "        return self.out_lmbda\n",
    "    \n",
    "    def huber_scale(self):\n",
    "        r = self.z - var_nodes[self.var_id].get_mu()\n",
    "        M = torch.sqrt(r * self.lmbda_in[0,0] * r)\n",
    "\n",
    "        if M > self.N_sigma:\n",
    "            kR = (2 * self.N_sigma / M) - (self.N_sigma ** 2 / M ** 2)\n",
    "            return kR\n",
    "        \n",
    "        return 1\n",
    "\n",
    "    def compute_messages(self):\n",
    "        kR = self.huber_scale()\n",
    "        self.out_eta, self.out_lmbda = self.eta * kR, self.lmbda * kR\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Observation factor with connected to {self.var_id} and z = {self.z} '\n",
    "\n",
    "class DynamicsFactor:\n",
    "    ''' Et_id is the id of E_t, Etp_id is the id of E_{t+1}'''\n",
    "    def __init__(self, f_id, lmbda_in, Et_id, Etp_id, beta = 0.):\n",
    "        self.Et_id = Et_id\n",
    "        self.Etp_id = Etp_id\n",
    "        self.f_id = f_id\n",
    "        self.lmbda_in = lmbda_in\n",
    "\n",
    "        self.out_eta = torch.tensor([[0.0]])\n",
    "        self.out_lmbda = torch.tensor([[0.0]])\n",
    "\n",
    "        # Message damping\n",
    "        self.prev_msg_right = None\n",
    "        self.prev_msg_left = None\n",
    "        self.beta = beta  # Damping constant\n",
    "\n",
    "        self.N_sigma = torch.sqrt(lmbda_in[0,0])\n",
    "\n",
    "        # self.update_eta_lmbda()\n",
    "    \n",
    "    def update_eta_lmbda(self):\n",
    "        Et = var_nodes[self.Et_id].get_mu()[0,0].clone().detach().requires_grad_(True)\n",
    "        Etp = var_nodes[self.Etp_id].get_mu()[0,0].clone().detach().requires_grad_(True)\n",
    "        print(f'Using {Et} and {Etp} to calculate...')\n",
    "        self.h = torch.abs(Etp - (Et + dedt(Et)))\n",
    "        self.h.backward()\n",
    "\n",
    "        J = torch.tensor([[Et.grad, Etp.grad]])\n",
    "        print('h', self.h, J)\n",
    "\n",
    "        x0 = torch.tensor([Et, Etp])\n",
    "        self.eta = J.T @ self.lmbda_in * ((J @ x0) - self.h) \n",
    "        self.lmbdap = (J.T @ self.lmbda_in) @ J\n",
    "\n",
    "        print(self.eta.shape, self.lmbdap.shape)\n",
    "\n",
    "    def get_eta(self): \n",
    "        return self.out_eta\n",
    "\n",
    "    def get_lmbda(self):\n",
    "        return self.out_lmbda\n",
    "    \n",
    "    def huber_scale(self):\n",
    "        r = 0 - (self.h)\n",
    "        M = torch.sqrt(r * self.lmbda_in[0,0] * r)\n",
    "\n",
    "        if M > self.N_sigma:\n",
    "            k_r = (2 * self.N_sigma / M) - (self.N_sigma ** 2 / M ** 2)\n",
    "            return k_r\n",
    "        \n",
    "        return 1\n",
    "\n",
    "    def _compute_message_going_left(self):\n",
    "        self.update_eta_lmbda()\n",
    "\n",
    "        in_eta, in_lmbda = var_nodes[self.Etp_id].get_eta(), var_nodes[self.Etp_id].get_lmbda()\n",
    "        k_r = self.huber_scale()\n",
    "\n",
    "        # Compute the eta and lambda by var-factor rule and then scale\n",
    "        eta_here, lambda_here = torch.clone(self.eta), torch.clone(self.lmbdap)\n",
    "\n",
    "        eta_here[1] = self.eta[1] + in_eta\n",
    "        lambda_here[1,1] = self.lmbdap[1,1] + in_lmbda\n",
    "\n",
    "        eta_here *= k_r\n",
    "        lambda_here *= k_r\n",
    "\n",
    "        eta_a = eta_here[0]\n",
    "        eta_b = eta_here[1]\n",
    "        lambda_aa = lambda_here[0][0]\n",
    "        lambda_ab = lambda_here[0][1]\n",
    "        lambda_ba = lambda_here[1][0]\n",
    "        lambda_bb = lambda_here[1][1]\n",
    "\n",
    "        # Eq. 2.60 and 2.61 in Ortiz. 2003\n",
    "        lambda_ab_lambda_bbinv = lambda_ab / lambda_bb\n",
    "        out_eta = torch.tensor([eta_a - (lambda_ab_lambda_bbinv * eta_b)])\n",
    "        out_lmbda = torch.tensor([lambda_aa - (lambda_ab_lambda_bbinv * lambda_ba)]) \n",
    "\n",
    "        print(out_eta, out_lmbda, self.beta)\n",
    "\n",
    "        if self.prev_msg_left is not None:\n",
    "            out_eta = self.beta * out_eta + (1 - self.beta) * self.prev_msg_left[0]\n",
    "            out_lmbda = self.beta * out_lmbda + (1 - self.beta) * self.prev_msg_left[1]\n",
    "\n",
    "        self.out_lmbda = out_lmbda\n",
    "        self.out_eta = out_eta\n",
    "\n",
    "    def compute_messages(self):\n",
    "        self._compute_message_going_left()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Dynamics Factor {self.f_id} connecting {self.Et_id} to {self.Etp_id} with eta = {self.out_eta} and lambda = {self.out_lmbda}'\n",
    "\n",
    "def print_fg(vars, factors):\n",
    "    for i, j in zip(vars, factors):\n",
    "        print(vars[i])\n",
    "        print(factors[j])\n",
    "\n",
    "def update_observational_factor(key):\n",
    "    if not isinstance(key, tuple):\n",
    "        factor_nodes[key].compute_messages()\n",
    "\n",
    "def update_variable_belief(key):\n",
    "    var_nodes[key].compute_messages()\n",
    "\n",
    "def update_dynamics_factor(key):\n",
    "    if isinstance(key, tuple):\n",
    "        factor_nodes[key].compute_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_nodes, factor_nodes = {}, {}\n",
    "\n",
    "sigma_smoothness = 1.\n",
    "sigma_obs = 0.3\n",
    "\n",
    "signal = [0.2, 0.8, 1.0, 1.0, 1.0]\n",
    "\n",
    "r = .2\n",
    "tau_E = 1.\n",
    "P = .2\n",
    "k = 5.\n",
    "\n",
    "t = [1,2,3,4,5]\n",
    "\n",
    "E0 = 0.\n",
    "\n",
    "for i in range(len(t)):\n",
    "    var_nodes[i] = Variable(i, torch.tensor([[E0]], requires_grad=True), torch.tensor([[0.0]], requires_grad=True), -1 if i == 0 else (i-1, i), -1 if i+1 == len(t) else (i, i+1), i)\n",
    "    factor_nodes[i] = ObservationFactor(i, i, signal[i], torch.tensor([[sigma_obs ** -2]]))\n",
    "\n",
    "for i in range(len(t)):\n",
    "    if i+1 < len(t):\n",
    "        factor_nodes[(i, i+1)] = DynamicsFactor((i, i+1), torch.tensor([[sigma_smoothness ** -2]]), i, i+1, 1.)\n",
    "\n",
    "for i in range(25):\n",
    "    print(f'-------- ITERATION {i} ----------')\n",
    "    update_observational_factor(0)\n",
    "    update_observational_factor(1)\n",
    "    update_observational_factor(2)\n",
    "    update_variable_belief(0)\n",
    "    update_variable_belief(1)\n",
    "    update_variable_belief(2)\n",
    "    print('here', var_nodes[0].get_eta(), var_nodes[0].get_lmbda(), var_nodes[0].get_mu())\n",
    "    print('here', var_nodes[1].get_eta(), var_nodes[1].get_lmbda(), var_nodes[1].get_mu())\n",
    "    print('here', var_nodes[2].get_eta(), var_nodes[2].get_lmbda(), var_nodes[2].get_mu())\n",
    "    update_dynamics_factor((0,1))\n",
    "    update_dynamics_factor((1,2))\n",
    "    print(factor_nodes[(0,1)].get_eta(), factor_nodes[(0,1)].get_lmbda())\n",
    "    print(factor_nodes[(1,2)].get_eta(), factor_nodes[(1,2)].get_lmbda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated belief [eta=tensor([[100.]]), lambda=tensor([[100.]])]\n",
      "sending message to 0 [eta=tensor([[0.]]), lambda=tensor([[0.]])]\n",
      "sending message to (0, 1) [eta=tensor([[100.]]), lambda=tensor([[100.]])]\n",
      "marginalisation result [eta=tensor([[0.]], grad_fn=<SubBackward0>), lambda=tensor([[0.]])]\n",
      "sending message [eta=tensor([[0.],\n",
      "        [0.]], grad_fn=<AddBackward0>), lambda=tensor([[0., 0.],\n",
      "        [0., 0.]])]\n",
      "marginalisation result [eta=tensor([[202.0605]], grad_fn=<SubBackward0>), lambda=tensor([[403.1875]])]\n",
      "sending message [eta=tensor([[32.3297],\n",
      "        [32.3297]], grad_fn=<AddBackward0>), lambda=tensor([[64.5100, 64.5100],\n",
      "        [64.5100, 64.5100]])]\n"
     ]
    }
   ],
   "source": [
    "from fg.variables import Variable, Parameter\n",
    "from fg.factors import DynamicsFactor, ObservationFactor\n",
    "from fg.simulation_config import simulate_signal\n",
    "from fg.graph import Graph\n",
    "from fg.gaussian import Gaussian\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sigma_obs = 1e-1\n",
    "    sigma_dynamics = 1e-3\n",
    "    GT_k = 1.2\n",
    "    T, dt = 15, 0.01\n",
    "    iters = 20\n",
    "\n",
    "    # signal = simulate_signal(T, dt, GT_k)\n",
    "    signal = [1., 2., 3., 4.]\n",
    "    t = torch.arange(0, len(signal), 1)\n",
    "\n",
    "    # fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    factor_graph = Graph()\n",
    "\n",
    "    param_dict = {\n",
    "        # 'k': Parameter(len(t), Gaussian(torch.tensor([[1.0]]), torch.tensor([[2.]])), factor_graph, [])\n",
    "    }\n",
    "\n",
    "    # -- Construct FG -- #\n",
    "    # Add our variable and observation factors at each time step\n",
    "    for i in range(len(t)):\n",
    "        factor_graph.var_nodes[i] = Variable(i, Gaussian(torch.tensor([[0.]]), torch.tensor([[0.2]])), -1 if i == 0 else (i-1, i), -1 if i+1 == len(t) else (i,i+1), i, factor_graph)\n",
    "        factor_graph.factor_nodes[i] = ObservationFactor(i, i, signal[i], torch.tensor([[sigma_obs ** -2]]), factor_graph)\n",
    "\n",
    "    # Add our parmaters as additional variables to our factor graph\n",
    "    for _,p in param_dict.items():\n",
    "        factor_graph.param_ids.append(p.id)\n",
    "        factor_graph.var_nodes[p.id] = p\n",
    "\n",
    "    # Connect dynamics factors between timestep i and i+1 and connect each dyn. factor to our parameters\n",
    "    for i in range(len(t)):\n",
    "        if i+1 < len(t):\n",
    "            dyn_id = (i, i+1)\n",
    "            factor_graph.factor_nodes[dyn_id] = DynamicsFactor(i, i+1, torch.tensor([[sigma_dynamics ** -2]]), dyn_id, factor_graph)\n",
    "\n",
    "            for _,p in param_dict.items():\n",
    "                p.connected_factors.append(dyn_id)\n",
    "\n",
    "\n",
    "    # # # == RUN GBP (Sweep schedule) === #\n",
    "    # for iter in range(iters):\n",
    "    #     print(f'Iteration {iter}')\n",
    "    #     if iter == 0:\n",
    "    #         factor_graph.send_initial_parameter_messages()\n",
    "    #         factor_graph.update_all_observational_factors()\n",
    "\n",
    "    #     # -- RIGHT PASS --\n",
    "    #     for i in range(len(t)-1):\n",
    "    #         curr = factor_graph.var_nodes[i]\n",
    "\n",
    "    #         curr.compute_and_send_messages()\n",
    "\n",
    "    #         fac = factor_graph.factor_nodes[curr.right_id]\n",
    "\n",
    "    #         fac.compute_messages_except_key()\n",
    "\n",
    "    #     factor_graph.update_params()\n",
    "\n",
    "    #     # -- LEFT PASS --\n",
    "    #     for i in range(len(t)-1, 0, -1):\n",
    "    #         curr = factor_graph.var_nodes[i]\n",
    "\n",
    "    #         curr.compute_and_send_messages()\n",
    "\n",
    "    #         fac = factor_graph.factor_nodes[curr.left_id]\n",
    "\n",
    "    #         fac.compute_messages_except_key()\n",
    "\n",
    "    #     factor_graph.update_params()\n",
    "\n",
    "\n",
    "    # # Plotting results\n",
    "    # ax.plot(signal, label='Original Signal')\n",
    "    # recons_signal = torch.tensor([v.mean for k, v in factor_graph.var_nodes.items() if k not in factor_graph.param_ids])\n",
    "\n",
    "    # print(signal.shape, recons_signal.shape)\n",
    "\n",
    "    # ax.plot(recons_signal, label='GBP Result')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "factor_graph.send_initial_parameter_messages()\n",
    "factor_graph.update_all_observational_factors()\n",
    "\n",
    "i = 0\n",
    "curr = factor_graph.var_nodes[i]\n",
    "curr.compute_and_send_messages()\n",
    "fac = factor_graph.factor_nodes[curr.right_id]\n",
    "fac.compute_messages_except_key()\n",
    "\n",
    "i = 1\n",
    "# curr = factor_graph.var_nodes[i]\n",
    "# curr.compute_and_send_messages()\n",
    "# fac = factor_graph.factor_nodes[curr.right_id]\n",
    "# fac.compute_messages_except_key()\n",
    "\n",
    "# i = 2\n",
    "# curr = factor_graph.var_nodes[i]\n",
    "# curr.compute_and_send_messages()\n",
    "# fac = factor_graph.factor_nodes[curr.right_id]\n",
    "# fac.compute_messages_except_key()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, v in factor_graph.var_nodes.items():\n",
    "    print(v, v.inbox)\n",
    "\n",
    "for _, v in factor_graph.factor_nodes.items():\n",
    "    print(v.factor_id, v.inbox)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
