{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "def sig(x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return 2*sig(2*x) - 1\n",
    "\n",
    "def dedt(E):\n",
    "    # de = (-E + (1 - r*E)*sig(w_ee*E - w_ei*I + P)) / tau_E\n",
    "    de = (-E + sig(k*E + k*P)) / tau_E\n",
    "    return de\n",
    "\n",
    "\n",
    "class Variable:\n",
    "    def __init__(self, var_id, mu, sigma, left_dynamics_id, right_dynamics_id, obs_id):\n",
    "        self.var_id = var_id\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.eta = torch.zeros_like(mu, requires_grad=True)\n",
    "        self.lmbda = torch.zeros_like(sigma, requires_grad=True)\n",
    "\n",
    "        self.right_dynamics_id = right_dynamics_id\n",
    "        self.left_dynamics_id = left_dynamics_id\n",
    "        self.obs_id = obs_id\n",
    "\n",
    "        self.factors = [self.obs_id, self.left_dynamics_id, self.right_dynamics_id]\n",
    "\n",
    "        self.out_eta, self.out_lmbda = torch.zeros_like(mu), torch.zeros_like(sigma)\n",
    "\n",
    "    def get_eta(self):\n",
    "        return self.out_eta\n",
    "    \n",
    "    def get_mu(self):\n",
    "        return self.mu\n",
    "    \n",
    "    def get_lmbda(self):\n",
    "        return self.out_lmbda\n",
    "    \n",
    "    def get_sigma(self):\n",
    "        return self.sigma\n",
    "\n",
    "    def belief_update(self):\n",
    "        eta_here, lmbda_here = torch.tensor([[0.]]), torch.tensor([[0.]])\n",
    "\n",
    "        for fid in self.factors:\n",
    "            if fid == -1: continue\n",
    "\n",
    "            eta_here  += factor_nodes[fid].get_eta()\n",
    "            lmbda_here += factor_nodes[fid].get_lmbda()\n",
    "\n",
    "        if lmbda_here == 0.: print('We Hebben Een Serieus Probleem ')\n",
    "\n",
    "        self.out_eta, self.out_lmbda = eta_here, lmbda_here\n",
    "\n",
    "        self.sigma = torch.linalg.inv(self.out_lmbda)\n",
    "        self.mu = self.sigma @ self.out_eta\n",
    "\n",
    "    def compute_messages(self):\n",
    "        self.belief_update()\n",
    "\n",
    "        if self.right_dynamics_id == -1: return\n",
    "\n",
    "        in_eta, in_lmbda = factor_nodes[self.right_dynamics_id].get_eta(), factor_nodes[self.right_dynamics_id].get_lmbda()\n",
    "\n",
    "        self.out_eta -= in_eta \n",
    "        self.out_lmbda -= in_lmbda\n",
    "\n",
    "\n",
    "class ObservationFactor:\n",
    "    def __init__(self, f_id, var_id, z, lmbda_in):\n",
    "        self.f_id = f_id\n",
    "        self.z = z\n",
    "        self.lmbda_in = lmbda_in\n",
    "        self.var_id = var_id\n",
    "\n",
    "        # Jacobian\n",
    "        J = torch.tensor([[1.]])\n",
    "\n",
    "        self.eta = (J.T @ lmbda_in) * z\n",
    "        self.lmbda = (J.T @ lmbda_in) @ J\n",
    "        self.N_sigma = torch.sqrt(lmbda_in[0,0])\n",
    "\n",
    "        self.out_eta, self.out_lmbda = self.eta, self.lmbda\n",
    "    \n",
    "    def get_eta(self):\n",
    "        return self.out_eta\n",
    "\n",
    "    def get_lmbda(self):\n",
    "        return self.out_lmbda\n",
    "    \n",
    "    def huber_scale(self):\n",
    "        r = self.z - var_nodes[self.var_id].get_mu()\n",
    "        M = torch.sqrt(r * self.lmbda_in[0,0] * r)\n",
    "\n",
    "        if M > self.N_sigma:\n",
    "            kR = (2 * self.N_sigma / M) - (self.N_sigma ** 2 / M ** 2)\n",
    "            return kR\n",
    "        \n",
    "        return 1\n",
    "\n",
    "    def compute_messages(self):\n",
    "        kR = self.huber_scale()\n",
    "        self.out_eta, self.out_lmbda = self.eta * kR, self.lmbda * kR\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Observation factor with connected to {self.var_id} and z = {self.z} '\n",
    "\n",
    "class DynamicsFactor:\n",
    "    ''' Et_id is the id of E_t, Etp_id is the id of E_{t+1}'''\n",
    "    def __init__(self, f_id, lmbda_in, Et_id, Etp_id, beta = 0.):\n",
    "        self.Et_id = Et_id\n",
    "        self.Etp_id = Etp_id\n",
    "        self.f_id = f_id\n",
    "        self.lmbda_in = lmbda_in\n",
    "\n",
    "        self.out_eta = torch.tensor([[0.0]])\n",
    "        self.out_lmbda = torch.tensor([[0.0]])\n",
    "\n",
    "        # Message damping\n",
    "        self.prev_msg_right = None\n",
    "        self.prev_msg_left = None\n",
    "        self.beta = beta  # Damping constant\n",
    "\n",
    "        self.N_sigma = torch.sqrt(lmbda_in[0,0])\n",
    "\n",
    "        # self.update_eta_lmbda()\n",
    "    \n",
    "    def update_eta_lmbda(self):\n",
    "        Et = var_nodes[self.Et_id].get_mu()[0,0].clone().detach().requires_grad_(True)\n",
    "        Etp = var_nodes[self.Etp_id].get_mu()[0,0].clone().detach().requires_grad_(True)\n",
    "        print(f'Using {Et} and {Etp} to calculate...')\n",
    "        self.h = torch.abs(Etp - (Et + dedt(Et)))\n",
    "        self.h.backward()\n",
    "\n",
    "        J = torch.tensor([[Et.grad, Etp.grad]])\n",
    "        print('h', self.h, J)\n",
    "\n",
    "        x0 = torch.tensor([Et, Etp])\n",
    "        self.eta = J.T @ self.lmbda_in * ((J @ x0) - self.h) \n",
    "        self.lmbdap = (J.T @ self.lmbda_in) @ J\n",
    "\n",
    "        print(self.eta.shape, self.lmbdap.shape)\n",
    "\n",
    "    def get_eta(self): \n",
    "        return self.out_eta\n",
    "\n",
    "    def get_lmbda(self):\n",
    "        return self.out_lmbda\n",
    "    \n",
    "    def huber_scale(self):\n",
    "        r = 0 - (self.h)\n",
    "        M = torch.sqrt(r * self.lmbda_in[0,0] * r)\n",
    "\n",
    "        if M > self.N_sigma:\n",
    "            k_r = (2 * self.N_sigma / M) - (self.N_sigma ** 2 / M ** 2)\n",
    "            return k_r\n",
    "        \n",
    "        return 1\n",
    "\n",
    "    def _compute_message_going_left(self):\n",
    "        self.update_eta_lmbda()\n",
    "\n",
    "        in_eta, in_lmbda = var_nodes[self.Etp_id].get_eta(), var_nodes[self.Etp_id].get_lmbda()\n",
    "        k_r = self.huber_scale()\n",
    "\n",
    "        # Compute the eta and lambda by var-factor rule and then scale\n",
    "        eta_here, lambda_here = torch.clone(self.eta), torch.clone(self.lmbdap)\n",
    "\n",
    "        eta_here[1] = self.eta[1] + in_eta\n",
    "        lambda_here[1,1] = self.lmbdap[1,1] + in_lmbda\n",
    "\n",
    "        eta_here *= k_r\n",
    "        lambda_here *= k_r\n",
    "\n",
    "        eta_a = eta_here[0]\n",
    "        eta_b = eta_here[1]\n",
    "        lambda_aa = lambda_here[0][0]\n",
    "        lambda_ab = lambda_here[0][1]\n",
    "        lambda_ba = lambda_here[1][0]\n",
    "        lambda_bb = lambda_here[1][1]\n",
    "\n",
    "        # Eq. 2.60 and 2.61 in Ortiz. 2003\n",
    "        lambda_ab_lambda_bbinv = lambda_ab / lambda_bb\n",
    "        out_eta = torch.tensor([eta_a - (lambda_ab_lambda_bbinv * eta_b)])\n",
    "        out_lmbda = torch.tensor([lambda_aa - (lambda_ab_lambda_bbinv * lambda_ba)]) \n",
    "\n",
    "        print(out_eta, out_lmbda, self.beta)\n",
    "\n",
    "        if self.prev_msg_left is not None:\n",
    "            out_eta = self.beta * out_eta + (1 - self.beta) * self.prev_msg_left[0]\n",
    "            out_lmbda = self.beta * out_lmbda + (1 - self.beta) * self.prev_msg_left[1]\n",
    "\n",
    "        self.out_lmbda = out_lmbda\n",
    "        self.out_eta = out_eta\n",
    "\n",
    "    def compute_messages(self):\n",
    "        self._compute_message_going_left()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Dynamics Factor {self.f_id} connecting {self.Et_id} to {self.Etp_id} with eta = {self.out_eta} and lambda = {self.out_lmbda}'\n",
    "\n",
    "def print_fg(vars, factors):\n",
    "    for i, j in zip(vars, factors):\n",
    "        print(vars[i])\n",
    "        print(factors[j])\n",
    "\n",
    "def update_observational_factor(key):\n",
    "    if not isinstance(key, tuple):\n",
    "        factor_nodes[key].compute_messages()\n",
    "\n",
    "def update_variable_belief(key):\n",
    "    var_nodes[key].compute_messages()\n",
    "\n",
    "def update_dynamics_factor(key):\n",
    "    if isinstance(key, tuple):\n",
    "        factor_nodes[key].compute_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- ITERATION 0 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.2000]])\n",
      "here tensor([[8.8889]]) tensor([[11.1111]]) tensor([[0.8000]])\n",
      "here tensor([[11.1111]]) tensor([[11.1111]]) tensor([[1.]])\n",
      "Using 0.20000000298023224 and 0.800000011920929 to calculate...\n",
      "h tensor(0.0808, grad_fn=<AbsBackward0>) tensor([[ 0.5250, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0117]) tensor([0.2528]) 1.0\n",
      "Using 0.800000011920929 and 1.0 to calculate...\n",
      "h tensor(0.0067, grad_fn=<AbsBackward0>) tensor([[-0.0332,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0010]) tensor([0.0010]) 1.0\n",
      "tensor([0.0117]) tensor([0.2528])\n",
      "tensor([0.0010]) tensor([0.0010])\n",
      "-------- ITERATION 1 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1966]])\n",
      "here tensor([[8.9005]]) tensor([[11.3639]]) tensor([[0.7832]])\n",
      "here tensor([[11.1121]]) tensor([[11.1121]]) tensor([[1.0000]])\n",
      "Using 0.19657568633556366 and 0.7832457423210144 to calculate...\n",
      "h tensor(0.0957, grad_fn=<AbsBackward0>) tensor([[ 0.5318, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0043]) tensor([0.2600]) 1.0\n",
      "Using 0.7832457423210144 and 1.0000001192092896 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0361,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0043]) tensor([0.2600])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 2 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1958]])\n",
      "here tensor([[8.8932]]) tensor([[11.3711]]) tensor([[0.7821]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19580505788326263 and 0.7821084856987 to calculate...\n",
      "h tensor(0.0965, grad_fn=<AbsBackward0>) tensor([[ 0.5334, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0039]) tensor([0.2615]) 1.0\n",
      "Using 0.7821084856987 and 0.9999983906745911 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0039]) tensor([0.2615])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 3 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8928]]) tensor([[11.3726]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19574379920959473 and 0.7819682359695435 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2616]) 1.0\n",
      "Using 0.7819682359695435 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2616])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 4 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3727]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573673605918884 and 0.7819547653198242 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819547653198242 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 5 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573603570461273 and 0.7819533348083496 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819533348083496 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 6 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 7 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 8 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 9 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 10 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 11 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 12 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 13 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 14 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 15 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 16 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 17 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 18 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 19 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 20 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 21 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 22 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 23 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n",
      "-------- ITERATION 24 ----------\n",
      "here tensor([[2.2222]]) tensor([[11.1111]]) tensor([[0.1957]])\n",
      "here tensor([[8.8927]]) tensor([[11.3728]]) tensor([[0.7820]])\n",
      "here tensor([[11.1123]]) tensor([[11.1123]]) tensor([[1.0000]])\n",
      "Using 0.19573596119880676 and 0.7819531559944153 to calculate...\n",
      "h tensor(0.0966, grad_fn=<AbsBackward0>) tensor([[ 0.5335, -1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0038]) tensor([0.2617]) 1.0\n",
      "Using 0.7819531559944153 and 0.999998152256012 to calculate...\n",
      "h tensor(0.0073, grad_fn=<AbsBackward0>) tensor([[-0.0363,  1.0000]])\n",
      "torch.Size([2, 1]) torch.Size([2, 2])\n",
      "tensor([0.0012]) tensor([0.0012]) 1.0\n",
      "tensor([0.0038]) tensor([0.2617])\n",
      "tensor([0.0012]) tensor([0.0012])\n"
     ]
    }
   ],
   "source": [
    "var_nodes, factor_nodes = {}, {}\n",
    "\n",
    "sigma_smoothness = 1.\n",
    "sigma_obs = 0.3\n",
    "\n",
    "signal = [0.2, 0.8, 1.0, 1.0, 1.0]\n",
    "\n",
    "r = .2\n",
    "tau_E = 1.\n",
    "P = .2\n",
    "k = 5.\n",
    "\n",
    "t = [1,2,3,4,5]\n",
    "\n",
    "E0 = 0.\n",
    "\n",
    "for i in range(len(t)):\n",
    "    var_nodes[i] = Variable(i, torch.tensor([[E0]], requires_grad=True), torch.tensor([[0.0]], requires_grad=True), -1 if i == 0 else (i-1, i), -1 if i+1 == len(t) else (i, i+1), i)\n",
    "    factor_nodes[i] = ObservationFactor(i, i, signal[i], torch.tensor([[sigma_obs ** -2]]))\n",
    "\n",
    "for i in range(len(t)):\n",
    "    if i+1 < len(t):\n",
    "        factor_nodes[(i, i+1)] = DynamicsFactor((i, i+1), torch.tensor([[sigma_smoothness ** -2]]), i, i+1, 1.)\n",
    "\n",
    "for i in range(25):\n",
    "    print(f'-------- ITERATION {i} ----------')\n",
    "    update_observational_factor(0)\n",
    "    update_observational_factor(1)\n",
    "    update_observational_factor(2)\n",
    "    update_variable_belief(0)\n",
    "    update_variable_belief(1)\n",
    "    update_variable_belief(2)\n",
    "    print('here', var_nodes[0].get_eta(), var_nodes[0].get_lmbda(), var_nodes[0].get_mu())\n",
    "    print('here', var_nodes[1].get_eta(), var_nodes[1].get_lmbda(), var_nodes[1].get_mu())\n",
    "    print('here', var_nodes[2].get_eta(), var_nodes[2].get_lmbda(), var_nodes[2].get_mu())\n",
    "    update_dynamics_factor((0,1))\n",
    "    update_dynamics_factor((1,2))\n",
    "    print(factor_nodes[(0,1)].get_eta(), factor_nodes[(0,1)].get_lmbda())\n",
    "    print(factor_nodes[(1,2)].get_eta(), factor_nodes[(1,2)].get_lmbda())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
